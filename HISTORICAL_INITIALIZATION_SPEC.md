# Sp√©cification : Syst√®me d'initialisation historique des tokens

## Vue d'ensemble

Syst√®me permettant d'initialiser automatiquement les donn√©es OHLCV historiques (1 mois) pour les nouveaux tokens via l'API GeckoTerminal, avec gestion d'une file d'attente et respect du rate limit (30 req/min).

---

## 1. Modifications de la base de donn√©es SQLite

### 1.1 Ajout du statut "initializing"

Modifier la table `tokens` pour ajouter un nouveau statut et des m√©tadonn√©es d'initialisation :

```sql
-- Migration √† ajouter dans src/db-init.js

ALTER TABLE tokens ADD COLUMN initialization_status TEXT DEFAULT 'pending';
ALTER TABLE tokens ADD COLUMN initialization_started_at INTEGER;
ALTER TABLE tokens ADD COLUMN initialization_completed_at INTEGER;
ALTER TABLE tokens ADD COLUMN initialization_progress INTEGER DEFAULT 0;
ALTER TABLE tokens ADD COLUMN initialization_error TEXT;
ALTER TABLE tokens ADD COLUMN main_pool_id TEXT;

-- Valeurs possibles pour initialization_status:
-- 'pending'      : En attente d'initialisation
-- 'in_progress'  : Initialisation en cours
-- 'completed'    : Initialisation termin√©e avec succ√®s
-- 'failed'       : √âchec de l'initialisation (r√©essayable)
-- 'skipped'      : Pas d'initialisation n√©cessaire (token ajout√© manuellement par exemple)
```

### 1.2 Nouveau sch√©ma complet de la table

```javascript
// src/db-init.js - Nouveau sch√©ma

db.exec(`
  CREATE TABLE IF NOT EXISTS tokens (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    contract_address TEXT UNIQUE NOT NULL,
    symbol TEXT NOT NULL,
    is_active BOOLEAN DEFAULT 1,
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    last_update INTEGER,

    -- Nouveaux champs pour l'initialisation historique
    initialization_status TEXT DEFAULT 'pending',
    initialization_started_at INTEGER,
    initialization_completed_at INTEGER,
    initialization_progress INTEGER DEFAULT 0,
    initialization_error TEXT,
    main_pool_id TEXT,
    historical_data_start_date INTEGER,
    historical_data_end_date INTEGER
  )
`);
```

---

## 2. Architecture du syst√®me

### 2.1 Composants

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    API Routes (tokens.js)                    ‚îÇ
‚îÇ  POST /api/tokens ‚Üí Cr√©e token avec status 'pending'        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                SQLite Database (tokens table)                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Status: pending ‚Üí in_progress ‚Üí completed           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Queue: Tous les tokens avec status = 'pending'      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         HistoricalDataInitializer (nouveau service)          ‚îÇ
‚îÇ  - Traite 1 token √† la fois                                 ‚îÇ
‚îÇ  - Respect du rate limit (30 req/min)                       ‚îÇ
‚îÇ  - Retry automatique en cas d'√©chec                         ‚îÇ
‚îÇ  - Logging d√©taill√© de la progression                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              GeckoTerminal API Client                        ‚îÇ
‚îÇ  - getMainPoolId(tokenAddress)                              ‚îÇ
‚îÇ  - fetchOHLCVHistory(poolId, daysBack)                      ‚îÇ
‚îÇ  - Gestion des erreurs 429 (rate limit)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  InfluxDB (raw_prices + ohlcv)               ‚îÇ
‚îÇ  - Insertion des raw prices historiques                     ‚îÇ
‚îÇ  - Construction des bougies OHLCV selon vos r√®gles m√©tier   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Flux de traitement

```
1. POST /api/tokens (BROWNHOUSE)
   ‚Üì
2. Token cr√©√© avec initialization_status = 'pending'
   ‚Üì
3. HistoricalDataInitializer d√©tecte le nouveau token
   ‚Üì
4. Change status ‚Üí 'in_progress'
   ‚Üì
5. Appel GeckoTerminal API:
   a. R√©cup√®re le pool principal (1 requ√™te)
   b. R√©cup√®re l'historique OHLCV (44 requ√™tes pour 1 mois)
      ‚Üí Pause de 2s entre chaque requ√™te (rate limit)
   c. Stocke dans InfluxDB
   d. Construit les bougies OHLCV
   ‚Üì
6. Change status ‚Üí 'completed'
   ‚Üì
7. Token devient 'active' et rejoint les collecteurs temps r√©el
```

---

## 3. Impl√©mentation d√©taill√©e

### 3.1 Service HistoricalDataInitializer

**Fichier :** `src/services/HistoricalDataInitializer.js`

**Responsabilit√©s :**
- D√©tecter les tokens en attente d'initialisation
- Traiter un token √† la fois
- Respecter le rate limit (30 req/min)
- G√©rer les erreurs et retry
- Mettre √† jour le statut et la progression

**Configuration :**
```javascript
const config = {
  // Nombre de jours d'historique √† r√©cup√©rer
  HISTORICAL_DAYS: 30,

  // D√©lai entre chaque requ√™te GeckoTerminal (2s = 30 req/min)
  REQUEST_DELAY_MS: 2000,

  // Intervalle de v√©rification de la queue (toutes les 10 secondes)
  QUEUE_CHECK_INTERVAL_MS: 10000,

  // Nombre de retry en cas d'√©chec
  MAX_RETRIES: 3,

  // D√©lai avant retry (en minutes)
  RETRY_DELAY_MINUTES: 5
};
```

**Pseudo-code :**
```javascript
class HistoricalDataInitializer {
  constructor() {
    this.isProcessing = false;
    this.currentToken = null;
    this.queueInterval = null;
  }

  start() {
    // V√©rifier la queue toutes les 10 secondes
    this.queueInterval = setInterval(async () => {
      await this.processQueue();
    }, config.QUEUE_CHECK_INTERVAL_MS);
  }

  async processQueue() {
    // Si d√©j√† en train de traiter un token, skip
    if (this.isProcessing) {
      logger.debug('Traitement en cours, skip');
      return;
    }

    // R√©cup√©rer le prochain token en attente
    const token = await Token.getNextPendingInitialization();

    if (!token) {
      logger.debug('Aucun token en attente d\'initialisation');
      return;
    }

    // Traiter le token
    this.isProcessing = true;
    this.currentToken = token;

    try {
      await this.initializeToken(token);
    } catch (error) {
      logger.error(`Erreur lors de l'initialisation de ${token.symbol}:`, error);
    } finally {
      this.isProcessing = false;
      this.currentToken = null;
    }
  }

  async initializeToken(token) {
    logger.info(`üöÄ D√©but initialisation historique: ${token.symbol} (${token.contract_address})`);

    // 1. Marquer comme "in_progress"
    await Token.updateInitializationStatus(token.contract_address, {
      initialization_status: 'in_progress',
      initialization_started_at: Date.now(),
      initialization_progress: 0,
      initialization_error: null
    });

    try {
      // 2. R√©cup√©rer le pool principal (1 requ√™te)
      logger.info(`Recherche du pool principal pour ${token.symbol}...`);
      const poolId = await this.geckoTerminalClient.getMainPoolId(token.contract_address);

      await Token.update(token.contract_address, { main_pool_id: poolId });
      logger.info(`‚úÖ Pool trouv√©: ${poolId}`);

      // 3. R√©cup√©rer l'historique OHLCV (44 requ√™tes avec rate limit)
      logger.info(`R√©cup√©ration de ${config.HISTORICAL_DAYS} jours d'historique...`);

      const onProgress = (current, total) => {
        const progress = Math.floor((current / total) * 100);
        Token.updateInitializationStatus(token.contract_address, {
          initialization_progress: progress
        });
        logger.info(`üìä Progression ${token.symbol}: ${current}/${total} requ√™tes (${progress}%)`);
      };

      const candles = await this.geckoTerminalClient.fetchOHLCVHistory(
        poolId,
        config.HISTORICAL_DAYS,
        onProgress
      );

      logger.info(`‚úÖ ${candles.length} candles r√©cup√©r√©es pour ${token.symbol}`);

      // 4. Stocker dans InfluxDB et construire les bougies
      await this.storeHistoricalData(token, candles);

      // 5. Marquer comme "completed"
      await Token.updateInitializationStatus(token.contract_address, {
        initialization_status: 'completed',
        initialization_completed_at: Date.now(),
        initialization_progress: 100,
        historical_data_start_date: candles[candles.length - 1][0], // Plus ancien
        historical_data_end_date: candles[0][0] // Plus r√©cent
      });

      logger.info(`‚úÖ Initialisation termin√©e avec succ√®s: ${token.symbol}`);

    } catch (error) {
      // G√©rer l'√©chec
      logger.error(`‚ùå √âchec initialisation ${token.symbol}:`, error);

      await Token.updateInitializationStatus(token.contract_address, {
        initialization_status: 'failed',
        initialization_error: error.message,
        initialization_progress: 0
      });

      // TODO: Impl√©menter retry automatique apr√®s X minutes
    }
  }

  async storeHistoricalData(token, candles) {
    logger.info(`Stockage de ${candles.length} candles dans InfluxDB...`);

    // Les candles GeckoTerminal sont au format:
    // [timestamp, open, high, low, close, volume]

    // √âtape 1: Stocker les raw prices (pour coh√©rence avec le syst√®me existant)
    for (const candle of candles) {
      const [timestamp, open, high, low, close, volume] = candle;

      await writeRawPrice({
        token_address: token.contract_address,
        symbol: token.symbol,
        price: close, // Prix de cl√¥ture
        timestamp: new Date(timestamp * 1000)
      });
    }

    logger.info(`‚úÖ Raw prices stock√©es`);

    // √âtape 2: Construire les bougies OHLCV selon vos r√®gles m√©tier
    // Regrouper par timeframe (1m, 5m, 15m, 1h, 4h, 1d)
    await this.buildOHLCVCandles(token, candles);

    logger.info(`‚úÖ Bougies OHLCV construites`);
  }

  async buildOHLCVCandles(token, rawCandles) {
    const timeframes = ['1m', '5m', '15m', '1h', '4h', '1d'];

    for (const timeframe of timeframes) {
      logger.info(`Construction des bougies ${timeframe} pour ${token.symbol}...`);

      // Agr√©ger les candles minute selon le timeframe
      const aggregatedCandles = this.aggregateCandles(rawCandles, timeframe);

      // Calculer RSI et EMA pour chaque bougie
      for (let i = 0; i < aggregatedCandles.length; i++) {
        const candle = aggregatedCandles[i];

        // Calculer RSI et EMA avec l'historique pr√©c√©dent
        const previousCandles = aggregatedCandles.slice(0, i);
        const { rsi, rsi_quality } = this.calculateRSI([...previousCandles, candle]);
        const ema = this.calculateEMA([...previousCandles, candle].map(c => c.close));

        // Stocker dans InfluxDB
        await writeOHLCV({
          token_address: token.contract_address,
          symbol: token.symbol,
          timeframe,
          open: candle.open,
          high: candle.high,
          low: candle.low,
          close: candle.close,
          volume: candle.volume,
          quality_factor: 1.0, // Donn√©es historiques = qualit√© maximale
          timestamp: new Date(candle.timestamp * 1000),
          rsi: rsi || null,
          rsi_quality: rsi_quality || 0,
          ema: ema || null
        });
      }

      logger.info(`‚úÖ ${aggregatedCandles.length} bougies ${timeframe} cr√©√©es`);
    }
  }

  aggregateCandles(minuteCandles, timeframe) {
    // Convertir timeframe en minutes
    const timeframeMinutes = {
      '1m': 1,
      '5m': 5,
      '15m': 15,
      '1h': 60,
      '4h': 240,
      '1d': 1440
    }[timeframe];

    // Regrouper les candles par p√©riode
    const aggregated = [];
    const candlesByPeriod = {};

    for (const candle of minuteCandles) {
      const [timestamp, open, high, low, close, volume] = candle;

      // Arrondir le timestamp √† la p√©riode
      const periodStart = Math.floor(timestamp / (timeframeMinutes * 60)) * (timeframeMinutes * 60);

      if (!candlesByPeriod[periodStart]) {
        candlesByPeriod[periodStart] = [];
      }

      candlesByPeriod[periodStart].push({ timestamp, open, high, low, close, volume });
    }

    // Agr√©ger chaque p√©riode
    for (const [periodStart, candles] of Object.entries(candlesByPeriod)) {
      aggregated.push({
        timestamp: parseInt(periodStart),
        open: candles[0].open,
        high: Math.max(...candles.map(c => c.high)),
        low: Math.min(...candles.map(c => c.low)),
        close: candles[candles.length - 1].close,
        volume: candles.reduce((sum, c) => sum + c.volume, 0)
      });
    }

    return aggregated.sort((a, b) => a.timestamp - b.timestamp);
  }

  // R√©utiliser les m√©thodes existantes de CandleBuilder
  calculateRSI(candles) {
    // Copier la logique de src/services/CandleBuilder.js
    // ...
  }

  calculateEMA(prices) {
    // Copier la logique de src/services/CandleBuilder.js
    // ...
  }

  stop() {
    if (this.queueInterval) {
      clearInterval(this.queueInterval);
      this.queueInterval = null;
    }
    logger.info('HistoricalDataInitializer arr√™t√©');
  }
}

module.exports = HistoricalDataInitializer;
```

---

### 3.2 Client GeckoTerminal API

**Fichier :** `src/clients/GeckoTerminalClient.js`

```javascript
const fetch = require('cross-fetch');
const logger = require('../config/logger');

class GeckoTerminalClient {
  constructor() {
    this.baseUrl = 'https://api.geckoterminal.com/api/v2';
    this.requestDelay = 2000; // 2 secondes = 30 req/min
    this.lastRequestTime = 0;
  }

  async sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  async rateLimitedRequest(url) {
    // Respecter le rate limit (30 req/min = 1 req/2s)
    const now = Date.now();
    const timeSinceLastRequest = now - this.lastRequestTime;

    if (timeSinceLastRequest < this.requestDelay) {
      const waitTime = this.requestDelay - timeSinceLastRequest;
      logger.debug(`Rate limit: attente de ${waitTime}ms...`);
      await this.sleep(waitTime);
    }

    this.lastRequestTime = Date.now();

    const response = await fetch(url);

    if (response.status === 429) {
      logger.warn('Rate limit 429 atteint, attente de 60 secondes...');
      await this.sleep(60000);
      return this.rateLimitedRequest(url); // Retry
    }

    if (!response.ok) {
      throw new Error(`GeckoTerminal API error: ${response.status} ${response.statusText}`);
    }

    return response.json();
  }

  async getMainPoolId(tokenAddress) {
    logger.debug(`Recherche du pool principal pour ${tokenAddress}...`);

    const url = `${this.baseUrl}/networks/solana/tokens/${tokenAddress}`;
    const data = await this.rateLimitedRequest(url);

    if (!data.data || !data.data.relationships || !data.data.relationships.top_pools) {
      throw new Error(`Aucun pool trouv√© pour le token ${tokenAddress}`);
    }

    const topPools = data.data.relationships.top_pools.data;

    if (topPools.length === 0) {
      throw new Error(`Aucun pool actif pour le token ${tokenAddress}`);
    }

    // Retourner le pool principal (le plus liquide)
    const mainPoolId = topPools[0].id.replace('solana_', '');

    logger.debug(`Pool principal trouv√©: ${mainPoolId}`);
    return mainPoolId;
  }

  async fetchOHLCVHistory(poolId, daysBack = 30, onProgress = null) {
    logger.info(`R√©cup√©ration de ${daysBack} jours d'historique pour le pool ${poolId}...`);

    const allCandles = [];
    let beforeTimestamp = Math.floor(Date.now() / 1000);
    const targetTimestamp = beforeTimestamp - (daysBack * 24 * 60 * 60);

    const minutesNeeded = daysBack * 24 * 60;
    const requestsNeeded = Math.ceil(minutesNeeded / 1000);
    let requestCount = 0;

    while (beforeTimestamp > targetTimestamp) {
      const url = `${this.baseUrl}/networks/solana/pools/${poolId}/ohlcv/minute?aggregate=1&before_timestamp=${beforeTimestamp}&limit=1000`;

      logger.debug(`Requ√™te ${requestCount + 1}/${requestsNeeded}: ${url}`);

      const data = await this.rateLimitedRequest(url);
      const candles = data.data.attributes.ohlcv_list;

      if (candles.length === 0) {
        logger.info(`Plus de donn√©es historiques disponibles (${allCandles.length} candles r√©cup√©r√©es)`);
        break;
      }

      allCandles.push(...candles);
      beforeTimestamp = candles[candles.length - 1][0]; // Dernier timestamp de ce batch
      requestCount++;

      // Callback de progression
      if (onProgress) {
        onProgress(requestCount, requestsNeeded);
      }

      logger.debug(`${candles.length} candles r√©cup√©r√©es, total: ${allCandles.length}`);
    }

    logger.info(`‚úÖ R√©cup√©ration termin√©e: ${allCandles.length} candles sur ${(allCandles.length / 60 / 24).toFixed(1)} jours`);

    return allCandles.reverse(); // Du plus ancien au plus r√©cent
  }
}

module.exports = GeckoTerminalClient;
```

---

### 3.3 Modifications du mod√®le Token

**Fichier :** `src/models/Token.js`

Ajouter les m√©thodes suivantes :

```javascript
// R√©cup√©rer le prochain token en attente d'initialisation
static getNextPendingInitialization() {
  const db = sqliteManager.getDb();
  const stmt = db.prepare(`
    SELECT * FROM tokens
    WHERE initialization_status = 'pending'
    ORDER BY created_at ASC
    LIMIT 1
  `);
  return stmt.get();
}

// Mettre √† jour le statut d'initialisation
static updateInitializationStatus(address, updates) {
  const db = sqliteManager.getDb();

  const fields = [];
  const values = [];

  Object.entries(updates).forEach(([key, value]) => {
    fields.push(`${key} = ?`);
    values.push(value);
  });

  values.push(address);

  const stmt = db.prepare(`
    UPDATE tokens
    SET ${fields.join(', ')}
    WHERE contract_address = ?
  `);

  stmt.run(...values);
  logger.debug(`Token ${address} mis √† jour:`, updates);
}

// R√©cup√©rer les statistiques d'initialisation
static getInitializationStats() {
  const db = sqliteManager.getDb();
  const stmt = db.prepare(`
    SELECT
      initialization_status,
      COUNT(*) as count
    FROM tokens
    GROUP BY initialization_status
  `);
  return stmt.all();
}
```

---

### 3.4 Modifications des routes

**Fichier :** `src/routes/tokens.js`

Modifier la route POST pour cr√©er le token en mode "initializing" :

```javascript
// POST /api/tokens - Ajoute un nouveau token
router.post('/',
    [/* ... validations ... */],
    validate,
    async (req, res) => {
        try {
            const { contract_address, symbol } = req.body;
            logger.info('POST /tokens - Tentative d\'ajout:', { contract_address, symbol });

            // V√©rifier si le token existe d√©j√†
            const existingToken = await Token.findByAddress(contract_address);
            if (existingToken) {
                logger.info('POST /tokens - Token existant:', existingToken);
                return res.status(409).json({
                    status: 'error',
                    message: 'Ce token existe d√©j√†'
                });
            }

            // Cr√©er le nouveau token avec status 'pending'
            const newToken = await Token.create(contract_address, symbol, {
                initialization_status: 'pending' // ‚¨ÖÔ∏è NOUVEAU
            });

            // NE PAS ajouter aux collecteurs temps r√©el tout de suite
            // Ils seront ajout√©s automatiquement apr√®s l'initialisation

            logger.info('POST /tokens - Token cr√©√©, initialisation historique en attente:', newToken);
            res.status(201).json({
                status: 'success',
                message: 'Token ajout√© avec succ√®s. Initialisation historique en cours...',
                data: newToken
            });

        } catch (error) {
            logger.error('POST /tokens - Erreur:', error);
            res.status(500).json({
                status: 'error',
                message: 'Erreur lors de la cr√©ation du token',
                error: error.message
            });
        }
    }
);
```

**Nouvelle route pour suivre la progression :**

```javascript
// GET /api/tokens/:address/initialization-status
router.get('/:address/initialization-status', async (req, res) => {
    try {
        const { address } = req.params;

        const token = await Token.findByAddress(address);

        if (!token) {
            return res.status(404).json({
                status: 'error',
                message: 'Token non trouv√©'
            });
        }

        res.json({
            status: 'success',
            data: {
                initialization_status: token.initialization_status,
                initialization_progress: token.initialization_progress,
                initialization_started_at: token.initialization_started_at,
                initialization_completed_at: token.initialization_completed_at,
                initialization_error: token.initialization_error,
                historical_data_start_date: token.historical_data_start_date,
                historical_data_end_date: token.historical_data_end_date
            }
        });

    } catch (error) {
        logger.error('GET /tokens/:address/initialization-status - Erreur:', error);
        res.status(500).json({
            status: 'error',
            message: 'Erreur lors de la r√©cup√©ration du statut'
        });
    }
});
```

---

### 3.5 Int√©gration dans index.js

**Fichier :** `src/index.js`

```javascript
const HistoricalDataInitializer = require('./services/HistoricalDataInitializer');

// Cr√©ation de l'instance
const historicalInitializer = new HistoricalDataInitializer();

// D√©marrage apr√®s l'initialisation des collecteurs
async function initializeCollectors() {
    try {
        // ... code existant ...

        // D√©marrer l'initialisateur historique
        logger.info('D√©marrage du HistoricalDataInitializer...');
        await historicalInitializer.start();

        logger.info('Collecteurs initialis√©s avec succ√®s');
    } catch (error) {
        logger.error('Erreur lors de l\'initialisation des collecteurs:', error);
        process.exit(1);
    }
}

// Gestion de l'arr√™t propre
process.on('SIGTERM', () => {
    // ... code existant ...

    // Arr√™ter l'initialisateur
    historicalInitializer.stop();

    // ... code existant ...
});
```

---

## 4. Gestion des tokens "completed"

### 4.1 Activation automatique apr√®s initialisation

Une fois l'initialisation termin√©e (`status = 'completed'`), ajouter automatiquement le token aux collecteurs temps r√©el :

```javascript
// Dans HistoricalDataInitializer.js, apr√®s avoir marqu√© comme 'completed'

// Activer le token et l'ajouter aux collecteurs
await Token.update(token.contract_address, { is_active: true });

// R√©cup√©rer la liste des tokens actifs
const activeTokens = await Token.getAllActive();

// Mettre √† jour tous les collecteurs
if (priceCollector) {
  priceCollector.setTokens(activeTokens);
}
if (volumeCollector) {
  volumeCollector.setTokens(activeTokens);
}
if (candleBuilder) {
  candleBuilder.setTokens(activeTokens);
}

logger.info(`‚úÖ Token ${token.symbol} activ√© et ajout√© aux collecteurs temps r√©el`);
```

### 4.2 Requ√™te pour ne r√©cup√©rer que les tokens "active"

Modifier `Token.getAllActive()` pour ne retourner que les tokens avec `is_active = true` ET `initialization_status = 'completed'` :

```javascript
static getAllActive() {
  const db = sqliteManager.getDb();
  const stmt = db.prepare(`
    SELECT * FROM tokens
    WHERE is_active = 1
      AND (initialization_status = 'completed' OR initialization_status = 'skipped')
    ORDER BY created_at DESC
  `);
  return stmt.all();
}
```

---

## 5. Alternative : File RabbitMQ (si vraiment n√©cessaire)

### 5.1 Quand utiliser RabbitMQ ?

Uniquement si vous avez besoin de :
- **Haute disponibilit√©** : Plusieurs workers en parall√®le
- **Scalabilit√© horizontale** : Ajouter des workers dynamiquement
- **Clustering** : Distribuer la charge sur plusieurs serveurs

### 5.2 Architecture avec RabbitMQ

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API Routes       ‚îÇ
‚îÇ  POST /tokens      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   RabbitMQ Queue   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> ‚îÇ  Worker 1          ‚îÇ
‚îÇ  "token_init"      ‚îÇ         ‚îÇ  HistoricalInit    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚Üì                      ‚Üì                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Worker 2          ‚îÇ  ‚îÇ  Worker 3          ‚îÇ  ‚îÇ  Worker N          ‚îÇ
‚îÇ  HistoricalInit    ‚îÇ  ‚îÇ  HistoricalInit    ‚îÇ  ‚îÇ  HistoricalInit    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**docker-compose.yml :**
```yaml
services:
  rabbitmq:
    image: rabbitmq:3-management
    container_name: ohlcv-rabbitmq
    ports:
      - "5672:5672"   # AMQP
      - "15672:15672" # Management UI
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
    networks:
      - default
    restart: unless-stopped
```

**Co√ªt suppl√©mentaire :**
- M√©moire : ~150-200MB
- CPU : L√©ger overhead
- Complexit√© : Configuration, monitoring

---

## 6. Monitoring et observabilit√©

### 6.1 Logs

Tous les logs doivent √™tre structur√©s avec le module `winston` existant :

```javascript
logger.info('üìä Initialisation historique d√©marr√©e', {
  token: token.symbol,
  address: token.contract_address,
  daysBack: 30
});

logger.info('‚è≥ Progression', {
  token: token.symbol,
  progress: '45%',
  candles: 12000,
  requestsCompleted: 20,
  requestsTotal: 44
});

logger.info('‚úÖ Initialisation termin√©e', {
  token: token.symbol,
  candles: 26500,
  duration: '92s',
  dataRange: '2025-09-22 ‚Üí 2025-10-22'
});
```

### 6.2 Dashboard (optionnel)

Cr√©er une route pour afficher les statistiques :

```javascript
// GET /api/tokens/initialization-stats
router.get('/initialization-stats', async (req, res) => {
  const stats = await Token.getInitializationStats();

  res.json({
    status: 'success',
    data: {
      stats: stats,
      currentlyProcessing: historicalInitializer.currentToken || null
    }
  });
});
```

**Exemple de r√©ponse :**
```json
{
  "status": "success",
  "data": {
    "stats": [
      { "initialization_status": "pending", "count": 3 },
      { "initialization_status": "in_progress", "count": 1 },
      { "initialization_status": "completed", "count": 18 },
      { "initialization_status": "failed", "count": 2 }
    ],
    "currentlyProcessing": {
      "symbol": "HARAMBE",
      "progress": 67
    }
  }
}
```

---

## 7. Gestion des erreurs et retry

### 7.1 Types d'erreurs

| Erreur | Cause | Action |
|--------|-------|--------|
| **429 Too Many Requests** | Rate limit d√©pass√© | Attendre 60s et retry |
| **404 Not Found** | Token/pool introuvable | Marquer comme 'failed', ne pas retry |
| **Network error** | Timeout, DNS, etc. | Retry apr√®s 5 minutes |
| **InfluxDB error** | √âcriture √©chou√©e | Retry apr√®s 1 minute |

### 7.2 Strat√©gie de retry

```javascript
const RETRY_CONFIG = {
  maxRetries: 3,
  retryDelayMinutes: 5,
  retryableErrors: ['ECONNRESET', 'ETIMEDOUT', 'ENOTFOUND']
};

async initializeToken(token) {
  let retries = 0;

  while (retries < RETRY_CONFIG.maxRetries) {
    try {
      await this._doInitialize(token);
      return; // Succ√®s

    } catch (error) {
      retries++;

      if (!this.isRetryable(error) || retries >= RETRY_CONFIG.maxRetries) {
        // √âchec d√©finitif
        await Token.updateInitializationStatus(token.contract_address, {
          initialization_status: 'failed',
          initialization_error: error.message
        });
        throw error;
      }

      // Retry
      const delayMs = RETRY_CONFIG.retryDelayMinutes * 60 * 1000;
      logger.warn(`Retry ${retries}/${RETRY_CONFIG.maxRetries} dans ${RETRY_CONFIG.retryDelayMinutes} minutes...`);
      await this.sleep(delayMs);
    }
  }
}

isRetryable(error) {
  return RETRY_CONFIG.retryableErrors.some(code => error.code === code);
}
```

---

## 8. Tests et validation

### 8.1 Test manuel

```bash
# 1. Ajouter un nouveau token
curl -X POST http://localhost:3002/api/tokens \
  -H "Content-Type: application/json" \
  -d '{
    "contract_address": "AnR1qNfefHwL8GY7C4iqzBjJZyKzw6Z7N9kXY81bpump",
    "symbol": "BROWNHOUSE"
  }'

# 2. V√©rifier le statut d'initialisation
curl http://localhost:3002/api/tokens/AnR1qNfefHwL8GY7C4iqzBjJZyKzw6Z7N9kXY81bpump/initialization-status

# 3. Surveiller les logs
docker logs -f ohlcv-api | grep -i "brownhouse\|initialisation"

# 4. V√©rifier les donn√©es dans InfluxDB
# (via l'UI InfluxDB ou requ√™te API)
```

### 8.2 Validation des donn√©es

Apr√®s initialisation, v√©rifier que :
- ‚úÖ Les raw_prices sont pr√©sents dans InfluxDB
- ‚úÖ Les bougies OHLCV sont cr√©√©es pour tous les timeframes
- ‚úÖ Le RSI et l'EMA sont calcul√©s correctement
- ‚úÖ Le token est actif et collecte en temps r√©el

---

## 9. Timeline d'impl√©mentation (ce week-end)

### Samedi matin (2-3h)
1. ‚úÖ Migration SQLite (ajout des colonnes)
2. ‚úÖ Modification du mod√®le Token
3. ‚úÖ Cr√©ation du GeckoTerminalClient

### Samedi apr√®s-midi (3-4h)
4. ‚úÖ Impl√©mentation du HistoricalDataInitializer
5. ‚úÖ Int√©gration dans index.js
6. ‚úÖ Tests unitaires du client GeckoTerminal

### Dimanche matin (2-3h)
7. ‚úÖ Modification des routes (POST /tokens)
8. ‚úÖ Tests d'int√©gration avec un token r√©el
9. ‚úÖ Debugging et ajustements

### Dimanche apr√®s-midi (1-2h)
10. ‚úÖ Documentation finale
11. ‚úÖ Monitoring et logs
12. ‚úÖ Validation compl√®te sur plusieurs tokens

**Total estim√© : 8-12 heures**

---

## 10. Am√©liorations futures (post-MVP)

### Phase 2 (optionnel)
- üîÑ R√©-initialisation automatique si donn√©es incompl√®tes
- üìä Dashboard de monitoring dans le frontend
- üîî Notifications Slack/Email en cas d'√©chec
- üöÄ Parall√©lisation (plusieurs tokens en m√™me temps avec rate limit partag√©)
- üíæ Cache des pool IDs dans Redis pour performances

### Phase 3 (si n√©cessaire)
- üê∞ Migration vers RabbitMQ pour haute disponibilit√©
- üìà M√©triques Prometheus pour observabilit√©
- üîç Healthcheck HTTP pour l'initialisateur
- üåê Support de multiples sources de donn√©es (Birdeye en fallback)

---

## 11. Conclusion

### Pourquoi cette architecture ?

‚úÖ **Simple** : Pas de RabbitMQ, utilise SQLite d√©j√† pr√©sent
‚úÖ **Fiable** : Persistance des √©tats, retry automatique
‚úÖ **Performant** : Respect strict du rate limit, pas de blocage
‚úÖ **Observable** : Logs structur√©s, progression trackable
‚úÖ **Scalable** : Facile de passer √† RabbitMQ plus tard si besoin

### Risques et mitigations

| Risque | Probabilit√© | Impact | Mitigation |
|--------|-------------|--------|------------|
| Rate limit d√©pass√© | Faible | Moyen | D√©lai de 2s entre requ√™tes |
| Pool introuvable | Moyen | Faible | Marquer comme 'failed' |
| Donn√©es incompl√®tes | Moyen | Moyen | Logger l'historique r√©el disponible |
| Crash pendant init | Faible | Faible | Status 'in_progress' permet de reprendre |

---

**Auteur :** Claude Code
**Date :** 2025-10-22
**Version :** 1.0
