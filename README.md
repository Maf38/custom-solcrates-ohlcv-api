# Custom Solcrates OHLCV API

API personnalis√©e pour la collecte et l'analyse des donn√©es OHLCV (Open, High, Low, Close, Volume) des tokens Solana.

## Configuration

### Variables d'environnement

Cr√©ez un fichier `.env` √† la racine du projet avec les variables suivantes :

```env
# Server Configuration
PORT=3002

# Update Interval (in milliseconds)
UPDATE_INTERVAL=5000

# InfluxDB Configuration
INFLUXDB_URL=http://influxdb:8086
INFLUXDB_ADMIN_USER=admin
INFLUXDB_ADMIN_PASSWORD=adminpassword123
INFLUXDB_ORG=solcrates
INFLUXDB_BUCKET=ohlcv_data
INFLUXDB_TOKEN=my-super-secret-auth-token

# Logging Configuration
LOG_LEVEL=debug  # error, warn, info, http, verbose, debug, silly
LOG_FORMAT=json  # json ou simple
```

Ces variables sont utilis√©es √† la fois pour :
- L'initialisation d'InfluxDB
- La configuration de l'API OHLCV
- La communication entre les services

‚ö†Ô∏è En production, utilisez des mots de passe et tokens s√©curis√©s et ne les committez pas dans Git.

## D√©marrage

1. Cr√©ez votre fichier `.env` bas√© sur le template ci-dessus
2. D√©marrez les services :
   ```bash
   docker-compose up -d
   ```
3. V√©rifiez que tout fonctionne :
   - Interface InfluxDB : http://localhost:8086
   - API OHLCV : http://localhost:3002
   - Documentation API : http://localhost:3002/api-docs

## Structure des donn√©es

### Measurements InfluxDB

1. `raw_prices`
   - Fields:
     * price: float
   - Tags:
     * token_address: string
     * symbol: string

2. `raw_volumes`
   - Fields:
     * volume: float
   - Tags:
     * token_address: string
     * symbol: string

3. `ohlcv`
   - Fields:
     * open: float
     * high: float
     * low: float
     * close: float
     * volume: float
     * quality_factor: float
     * rsi_14: float (optionnel)
   - Tags:
     * token_address: string
     * symbol: string
     * timeframe: string (1m, 5m, 15m, 1h, 4h, 1d)

## M√©canisme de mise √† jour

1. **Donn√©es brutes** : 
   - Collecte toutes les X secondes (d√©fini par UPDATE_INTERVAL)
   - Prix via Jupiter API V3
   - Volumes via Solana RPC

2. **Construction des bougies** :
   - D√©clench√©e √† chaque minute
   - Utilise le modulo du timestamp pour d√©terminer quelles bougies construire
   - Exemple : 
     * Minute 0 : toutes les timeframes
     * Minute 5 : 1m, 5m
     * Minute 15 : 1m, 5m, 15m
     * etc.

3. **Facteur de qualit√©** :
   - Calcul√© pour chaque bougie
   - Repr√©sente le ratio de donn√©es disponibles vs attendues
   - Exemple pour 1m avec UPDATE_INTERVAL=5000 :
     * Attendu : 12 points (60s/5s)
     * Si 10 points disponibles : qualit√© = 0.83

## Calcul du RSI (Relative Strength Index)

### M√©thode de Wilder

Le RSI14 est calcul√© selon la m√©thode originale de J. Welles Wilder (1978), qui utilise un **lissage exponentiel** plut√¥t qu'une simple moyenne mobile.

### ‚ö†Ô∏è Important : Pourquoi 30 p√©riodes pour un RSI14 ?

Contrairement √† l'intuition, un **RSI14 n√©cessite 30 p√©riodes de donn√©es** pour √™tre calcul√© correctement selon la m√©thode de Wilder :

1. **P√©riodes 1-14** : Calcul de la moyenne simple (SMA) initiale
   - `avgGain = somme(gains sur 14 p√©riodes) / 14`
   - `avgLoss = somme(pertes sur 14 p√©riodes) / 14`

2. **P√©riodes 15-30** : Application du lissage exponentiel de Wilder
   - `avgGain = ((avgGain_pr√©c√©dent √ó 13) + gain_actuel) / 14`
   - `avgLoss = ((avgLoss_pr√©c√©dent √ó 13) + perte_actuelle) / 14`

3. **Calcul final du RSI** :
   - `RS = avgGain / avgLoss`
   - `RSI = 100 - (100 / (1 + RS))`

### Exemples concrets

- **RSI14 sur 1h** : N√©cessite 30 heures d'historique (30 bougies 1h)
- **RSI14 sur 4h** : N√©cessite 120 heures d'historique (30 bougies 4h)
- **RSI14 sur 1d** : N√©cessite 30 jours d'historique (30 bougies 1d)

### Facteur de qualit√© du RSI

Le `rsi_quality` refl√®te la fiabilit√© du calcul RSI :

- **Qualit√© = 100%** : 31 bougies disponibles (30 pr√©c√©dentes + actuelle), aucun gap
- **Qualit√© < 100%** : P√©nalit√©s appliqu√©es si :
  - Moins de 31 bougies disponibles (ex: 20/31 = 64.5%)
  - Bougies manquantes d√©tect√©es (gaps temporels)
  - Qualit√© individuelle des bougies faible

### Gestion des donn√©es insuffisantes

- **Minimum absolu** : 2 bougies (1 variation) ‚Üí RSI calcul√© mais qualit√© tr√®s basse
- **Donn√©es partielles** : Si moins de 14 variations ‚Üí utilise SMA simple (pas de lissage)
- **Donn√©es compl√®tes** : 30+ variations ‚Üí lissage de Wilder complet appliqu√©

## Architecture des donn√©es

### SQLite (Source de v√©rit√© pour les tokens)
- **Base de donn√©es** : `data/tokens.db`
- **Table principale** : `tokens` (contract_address, symbol, is_active, created_at, updated_at)
- **R√¥le** : D√©termine quels tokens sont suivis pour l'acquisition des donn√©es

### InfluxDB (Stockage des donn√©es temporelles)
- **Measurements** :
  - `raw_prices` : Prix bruts collect√©s
  - `raw_volumes` : Volumes bruts collect√©s  
  - `ohlcv` : Bougies OHLCV calcul√©es avec RSI
- **R√¥le** : Stockage pur des donn√©es temporelles, pas de logique m√©tier

### Flux de donn√©es
1. **Ajout d'un token** ‚Üí SQLite ‚Üí D√©marrage automatique de l'acquisition
2. **Acquisition** ‚Üí Donn√©es brutes dans InfluxDB
3. **Construction des bougies** ‚Üí Calcul OHLCV + RSI ‚Üí InfluxDB
4. **API** ‚Üí SQLite pour la liste des tokens, InfluxDB pour les donn√©es

## üÜï Syst√®me d'Initialisation Historique

### Vue d'ensemble

Lorsqu'un nouveau token est ajout√©, le syst√®me initialise **automatiquement** 30 jours de donn√©es historiques via l'API GeckoTerminal avant de d√©marrer la collecte en temps r√©el.

### Flux d'initialisation

```
1. POST /api/tokens (nouveau token)
   ‚Üì
2. Status: 'pending' ‚Üí Token cr√©√© mais pas encore actif
   ‚Üì
3. HistoricalDataInitializer d√©marre
   - Recherche du pool principal sur GeckoTerminal
   - T√©l√©chargement de 30 jours de bougies 1m (~43,200 bougies)
   - Respect du rate limit (30 req/min = 1 req/2s)
   ‚Üì
4. Traitement des donn√©es historiques
   - Conversion des bougies en raw_prices (prix de cl√¥ture)
   - Agr√©gation pour tous les timeframes (1m, 5m, 15m, 1h, 4h, 1d)
   - Calcul du RSI et EMA pour chaque bougie
   ‚Üì
5. Status: 'completed' ‚Üí Token activ√© automatiquement
   ‚Üì
6. Collecte en temps r√©el d√©marre
```

### Architecture des donn√©es historiques

#### √âtape 1 : R√©cup√©ration depuis GeckoTerminal
- **Format re√ßu** : Bougies 1 minute `[timestamp, open, high, low, close, volume]`
- **Quantit√©** : ~43,200 bougies pour 30 jours
- **Rate limit** : 30 requ√™tes/minute (2 secondes entre chaque requ√™te)
- **Dur√©e** : ~2-3 minutes pour r√©cup√©rer tout l'historique

#### √âtape 2 : Conversion en raw_prices
Pour chaque bougie 1m re√ßue :
```javascript
await writeRawPrice({
    token_address: "...",
    symbol: "...",
    price: close,  // Prix de cl√¥ture de la bougie
    timestamp: new Date(timestamp * 1000)
});
```

**Pourquoi ?** Maintenir la coh√©rence avec le syst√®me de collecte en temps r√©el qui utilise des raw_prices comme base.

#### √âtape 3 : Construction des bougies OHLCV
Les bougies 1 minute sont agr√©g√©es pour cr√©er tous les timeframes :

| Timeframe | Agr√©gation | Bougies cr√©√©es (30j) |
|-----------|------------|---------------------|
| 1m | Directe | ~43,200 |
| 5m | 5 bougies 1m | ~8,640 |
| 15m | 15 bougies 1m | ~2,880 |
| 1h | 60 bougies 1m | ~720 |
| 4h | 240 bougies 1m | ~180 |
| 1d | 1,440 bougies 1m | ~30 |

Pour chaque bougie agr√©g√©e :
- **OHLC** : Open (premi√®re), High (max), Low (min), Close (derni√®re)
- **Volume** : Somme des volumes
- **RSI** : Calcul√© avec l'historique pr√©c√©dent (m√©thode de Wilder)
- **EMA** : Calcul√© avec l'historique pr√©c√©dent
- **Quality Factor** : 1.0 (donn√©es historiques = qualit√© maximale)

### √âtats d'initialisation

| Status | Description |
|--------|-------------|
| `pending` | En attente de traitement |
| `in_progress` | Initialisation en cours |
| `completed` | Termin√© avec succ√®s, token actif |
| `failed` | √âchec (erreur stock√©e) |
| `skipped` | Pas d'initialisation n√©cessaire (tokens existants) |

### Sch√©ma de la table tokens

```sql
CREATE TABLE tokens (
    -- Colonnes de base
    contract_address TEXT PRIMARY KEY,
    symbol TEXT NOT NULL,
    is_active BOOLEAN DEFAULT true,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,

    -- Colonnes d'initialisation historique
    initialization_status TEXT DEFAULT 'pending',
    initialization_started_at INTEGER,
    initialization_completed_at INTEGER,
    initialization_progress INTEGER DEFAULT 0,
    initialization_error TEXT,
    main_pool_id TEXT,
    historical_data_start_date INTEGER,
    historical_data_end_date INTEGER
);
```

### Configuration

Dans `src/services/HistoricalDataInitializer.js` :

```javascript
config = {
    HISTORICAL_DAYS: 30,              // Jours d'historique √† r√©cup√©rer
    REQUEST_DELAY_MS: 2000,           // D√©lai entre requ√™tes (rate limit)
    QUEUE_CHECK_INTERVAL_MS: 10000,   // V√©rification de la queue
    MAX_RETRIES: 3,                   // Tentatives en cas d'√©chec
    RETRY_DELAY_MINUTES: 5            // D√©lai avant retry
};
```

### Gestion des erreurs

| Erreur | Action |
|--------|--------|
| 429 Too Many Requests | Attente de 60s puis retry automatique |
| 404 Pool Not Found | Status 'failed', pas de retry |
| Network timeout | Retry apr√®s 5 minutes (max 3 fois) |
| InfluxDB error | Retry apr√®s 1 minute |

## API Routes

Documentation compl√®te disponible via Swagger UI : http://localhost:3002/api-docs

### Gestion des tokens

- `POST /api/tokens` : Ajouter un nouveau token (d√©marre l'initialisation historique puis l'acquisition)
- `GET /api/tokens` : Liste tous les tokens actifs (uniquement ceux avec status 'completed' ou 'skipped')
- `GET /api/tokens/all` : Liste tous les tokens (actifs et inactifs)
- `GET /api/tokens/:address` : R√©cup√®re un token sp√©cifique
- `GET /api/tokens/:address/initialization-status` : R√©cup√®re le statut d'initialisation d'un token
- `GET /api/tokens/initialization-stats` : R√©cup√®re les statistiques globales d'initialisation
- `PATCH /api/tokens/:address/activate` : R√©active un token (reprend l'acquisition)
- `PATCH /api/tokens/:address/deactivate` : D√©sactive un token (arr√™te l'acquisition)
- `DELETE /api/tokens/:address` : Supprime d√©finitivement un token (conserve les donn√©es InfluxDB)

### Donn√©es OHLCV

- `GET /api/ohlcv/:address/:timeframe` : R√©cup√®re les donn√©es OHLCV
- `GET /api/ohlcv/raw/:address` : R√©cup√®re les donn√©es brutes (prix + volume)

### Exemples d'utilisation

#### Ajouter un token et suivre l'initialisation

```bash
# 1. Ajouter le token
curl -X POST http://localhost:3002/api/tokens \
  -H "Content-Type: application/json" \
  -d '{
    "contract_address": "AnR1qNfefHwL8GY7C4iqzBjJZyKzw6Z7N9kXY81bpump",
    "symbol": "BROWNHOUSE"
  }'

# 2. V√©rifier le statut d'initialisation
curl http://localhost:3002/api/tokens/AnR1qNfefHwL8GY7C4iqzBjJZyKzw6Z7N9kXY81bpump/initialization-status

# R√©ponse :
{
  "status": "success",
  "data": {
    "initialization_status": "in_progress",
    "initialization_progress": 45,
    "initialization_started_at": 1729740000000,
    "initialization_completed_at": null,
    "initialization_error": null,
    "historical_data_start_date": null,
    "historical_data_end_date": null,
    "main_pool_id": "abc123..."
  }
}

# 3. Voir les statistiques globales
curl http://localhost:3002/api/tokens/initialization-stats

# R√©ponse :
{
  "status": "success",
  "data": {
    "stats": [
      { "initialization_status": "pending", "count": 2 },
      { "initialization_status": "in_progress", "count": 1 },
      { "initialization_status": "completed", "count": 15 },
      { "initialization_status": "failed", "count": 1 }
    ]
  }
}
```

#### Surveiller les logs

```bash
# Logs de l'initialisation historique
docker logs ohlcv-api -f | grep -i "initialisation\|historical"

# Exemple de logs :
# üöÄ D√©but initialisation historique: BROWNHOUSE (AnR1q...)
# Recherche du pool principal pour BROWNHOUSE...
# ‚úÖ Pool trouv√©: abc123...
# R√©cup√©ration de 30 jours d'historique...
# üìä Progression BROWNHOUSE: 10/44 requ√™tes (22%)
# üìä Progression BROWNHOUSE: 20/44 requ√™tes (45%)
# ‚úÖ 43200 candles r√©cup√©r√©es pour BROWNHOUSE
# Stockage de 43200 candles dans InfluxDB...
# ‚úÖ 43200 raw prices stock√©es
# Construction des bougies 1m pour BROWNHOUSE...
# ‚úÖ 43200 bougies 1m cr√©√©es
# Construction des bougies 5m pour BROWNHOUSE...
# ‚úÖ 8640 bougies 5m cr√©√©es
# ...
# ‚úÖ Initialisation termin√©e avec succ√®s: BROWNHOUSE
# ‚úÖ Token BROWNHOUSE activ√©
# Mise √† jour des collecteurs avec 16 tokens actifs
```

## Service de Backup Automatique

### üîÑ **Fonctionnement**

Le service de backup automatique sauvegarde quotidiennement vos donn√©es :

- **Horaire** : Tous les jours √† 2h00 du matin
- **R√©tention** : 30 jours (suppression automatique des anciens backups)
- **Localisation** : `/workspace/backupBDD/` sur l'h√¥te

### üìä **Donn√©es sauvegard√©es**

1. **InfluxDB** : Toutes les donn√©es temporelles
   - Raw prices (prix bruts collect√©s)
   - Raw volumes (si activ√©)
   - Bougies OHLCV (tous timeframes : 1m, 5m, 15m, 1h, 4h, 1d)
   - RSI et EMA calcul√©s
   - Donn√©es historiques initialis√©es (30 jours par token)

2. **SQLite** : Configuration des tokens
   - Informations de base (adresse, symbole, statut actif/inactif)
   - √âtat d'initialisation historique (status, progression, dates)
   - Pool IDs GeckoTerminal
   - M√©tadonn√©es de tra√ßabilit√©

### üöÄ **D√©marrage du service**

```bash
# D√©marrer le service de backup
docker compose up backup -d

# V√©rifier l'√©tat
docker ps --filter "name=backup"

# Voir les logs
docker logs ohlcv-backup-service -f
```

### üíæ **Backup manuel**

```bash
# Ex√©cuter un backup imm√©diat
docker exec ohlcv-backup-service /scripts/backup.sh

# Voir la liste des backups
ls -la /workspace/backupBDD/influxdb/
ls -la /workspace/backupBDD/sqlite/
```

### üîß **Configuration**

Le service utilise les m√™mes variables d'environnement que l'API :

```bash
INFLUXDB_URL=http://influxdb:8086
INFLUXDB_TOKEN=my-super-secret-auth-token
INFLUXDB_ORG=solcrates
INFLUXDB_BUCKET=ohlcv_data
```

### üîÑ **Restauration**

En cas de probl√®me, vous pouvez restaurer vos donn√©es :

```bash
# Lister les backups disponibles
ls /workspace/backupBDD/influxdb/

# Restaurer InfluxDB (choisir le backup souhait√©)
docker exec ohlcv-backup-service influx restore \
  /backups/influxdb/influxdb_backup_YYYYMMDD_HHMMSS.tar.gz \
  --host http://influxdb:8086 \
  --token $INFLUXDB_TOKEN \
  --org $INFLUXDB_ORG

# Restaurer SQLite
tar -xzf /workspace/backupBDD/sqlite/sqlite_backup_YYYYMMDD_HHMMSS.tar.gz -C ./data/
```

### üìà **Surveillance**

```bash
# Voir les logs du service backup
docker logs ohlcv-backup-service

# Voir l'espace utilis√© par les backups
docker exec ohlcv-backup-service du -sh /backups

# Voir les backups r√©cents
docker exec ohlcv-backup-service find /backups -name "*.tar.gz" -mtime -7
```

### ‚ö†Ô∏è **Important**

- Le service s'arr√™te automatiquement si InfluxDB n'est pas accessible
- Les backups sont compress√©s pour √©conomiser l'espace disque
- En cas de probl√®me, v√©rifiez les logs et les variables d'environnement

---

## Syst√®me d'Initialisation Historique

Lorsqu'un nouveau token est ajout√©, le syst√®me r√©cup√®re automatiquement **30 jours d'historique** depuis GeckoTerminal.

### Fonctionnement

1. **Ajout d'un token** via `POST /api/tokens`
   - Cr√©√© avec `is_active = false` et `initialization_status = 'pending'`
   - Plac√© dans la queue d'initialisation

2. **Traitement automatique** par `HistoricalDataInitializer`
   - R√©cup√®re le pool principal sur GeckoTerminal
   - T√©l√©charge les bougies minute des 30 derniers jours
   - Convertit en raw_prices pour coh√©rence avec la collecte temps r√©el
   - Construit les bougies OHLCV pour tous les timeframes (1m, 5m, 15m, 1h, 4h, 1d)
   - Calcule RSI et EMA pour chaque bougie
   - Active le token (`is_active = true`)

3. **Collecte temps r√©el** d√©marre automatiquement apr√®s initialisation

### Surveillance

```bash
# Voir les stats d'initialisation
curl http://localhost:3002/api/tokens/initialization-stats

# Voir le statut d'un token sp√©cifique
curl http://localhost:3002/api/tokens/{address}/initialization-status
```

### R√©sultats attendus

- **Gros tokens** (ex: MOODENG): ~40-50% de compl√©tude (beaucoup de transactions)
- **Petits tokens** (ex: SWOGE): ~5-10% de compl√©tude (peu de transactions)

**Note**: GeckoTerminal ne retourne que les minutes avec activit√©. Les gaps sont normaux pour les tokens peu liquides.

---

## Syst√®me de Rattrapage de Donn√©es (Backfill)

Le backfill permet de combler intelligemment les lacunes de donn√©es en 2 √©tapes :

### Strat√©gie

**√âtape 1 : Raw Prices**
- R√©cup√®re les bougies minute depuis GeckoTerminal
- V√©rifie quelles raw_prices existent d√©j√† en InfluxDB
- **Ins√®re uniquement les donn√©es manquantes** (pas de doublons)

**√âtape 2 : Recalcul S√©lectif**
- Parcourt chaque p√©riode de chaque timeframe
- **Skip si qualit√© OK** (quality_factor ‚â• 90% ET rsi_quality ‚â• 90%)
- **Recalcule** si qualit√© insuffisante
- **Cr√©e** si bougie manquante

### Gestion d'Erreurs Robuste

- **Retry automatique** avec backoff exponentiel (5s, 10s, 20s)
- **3 tentatives maximum** par op√©ration
- **Logs d√©taill√©s** de chaque tentative
- **Nettoyage automatique** du flag `isProcessing` m√™me en cas d'erreur

### API Endpoints

#### 1. Backfill d'un token

```bash
# Option A: P√©riode explicite
curl -X POST http://localhost:3002/api/backfill/token \
  -H "Content-Type: application/json" \
  -d '{
    "tokenAddress": "ADSXPGwP3riuvqYtwqogCD4Rfn1a6NASqaSpThpsmoon",
    "startDate": "2025-10-20T00:00:00Z",
    "endDate": "2025-10-22T23:59:59Z"
  }'

# Option B: Dur√©e relative (heures)
curl -X POST http://localhost:3002/api/backfill/token \
  -H "Content-Type: application/json" \
  -d '{
    "tokenAddress": "ADSXPGwP3riuvqYtwqogCD4Rfn1a6NASqaSpThpsmoon",
    "hours": 24
  }'

# Option C: Dur√©e relative (jours)
curl -X POST http://localhost:3002/api/backfill/token \
  -H "Content-Type: application/json" \
  -d '{
    "tokenAddress": "ADSXPGwP3riuvqYtwqogCD4Rfn1a6NASqaSpThpsmoon",
    "days": 7
  }'
```

#### 2. Backfill global (rupture de service)

```bash
# Rattraper les 6 derni√®res heures pour TOUS les tokens
curl -X POST http://localhost:3002/api/backfill/all \
  -H "Content-Type: application/json" \
  -d '{"hours": 6}'

# P√©riode sp√©cifique
curl -X POST http://localhost:3002/api/backfill/all \
  -H "Content-Type: application/json" \
  -d '{
    "startDate": "2025-10-23T12:00:00Z",
    "endDate": "2025-10-23T18:00:00Z"
  }'
```

#### 3. V√©rifier le statut

```bash
curl http://localhost:3002/api/backfill/status
```

### Cas d'usage

**Panne du service**
```bash
# Le service √©tait arr√™t√© du 23/10 12h au 23/10 18h
curl -X POST http://localhost:3002/api/backfill/all \
  -H "Content-Type: application/json" \
  -d '{
    "startDate": "2025-10-23T12:00:00Z",
    "endDate": "2025-10-23T18:00:00Z"
  }'
```

**Token avec donn√©es de mauvaise qualit√©**
```bash
# Am√©liorer la qualit√© RSI des 7 derniers jours
curl -X POST http://localhost:3002/api/backfill/token \
  -H "Content-Type: application/json" \
  -d '{
    "tokenAddress": "ADSXPGwP3riuvqYtwqogCD4Rfn1a6NASqaSpThpsmoon",
    "days": 7
  }'
```

### R√©ponse type

```json
{
  "status": "success",
  "message": "Backfill termin√© avec succ√®s",
  "data": {
    "token": "EMULITES",
    "period": {
      "start": "2025-10-25T06:16:14.957Z",
      "end": "2025-10-25T07:16:14.957Z"
    },
    "step1": {
      "candlesFromGecko": 45,
      "rawPricesInserted": 38,
      "rawPricesSkipped": 7
    },
    "step2": {
      "totalPeriods": 83,
      "candlesRecalculated": 64,
      "candlesSkipped": 16,
      "candlesCreated": 3
    },
    "duration": "8.5s",
    "success": true
  }
}
```

### Limitations

- **Un seul backfill √† la fois** (`isProcessing` emp√™che les conflits)
- **D√©pendant de GeckoTerminal** (si leurs donn√©es ont des gaps, on ne peut pas les combler)
- **Rate limiting** g√©r√© automatiquement (retry en cas de 429)

---